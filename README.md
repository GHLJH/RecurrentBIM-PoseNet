# RecurrentBIM-PoseNet
This is an implementation of Recurrent BIM-PoseNet for camera pose regression related to our upcoming work. More details will be available soon.  

The initial weight file (GoogleNet V1 trained on the Places dataset) can be found [here](https://melbourne.figshare.com/articles/GoogleNet_weights_trained_on_the_Places_dataset_for_Keras_/10959350).

The training and the test data can be found in [this](https://melbourne.figshare.com/articles/UnimelbCorridorSynthetic_zip/10930457) repository. 

## Dataset preview
[![Watch the video](https://melbourne.figshare.com/ndownloader/files/19441991/preview/19441991/preview.jpg)](https://melbourne.figshare.com/articles/UnimelbCorridorSynthetic_zip/10930457)

If you are using the dataset or any part of the code, please cite our works: 
- Acharya, D., Khoshelham, K., and Winter, S., 2019. BIM-PoseNet: Indoor camera localisation using a 3D indoor model and deep learning from synthetic images. ISPRS Journal of Photogrammetry and Remote Sensing. 150: 245-258.
- Acharya, D., Singha Roy, S., Khoshelham, K. and Winter, S. 2019. Modelling uncertainty of single image indoor localisation using a 3D model and deep learning. In ISPRS Annals of Photogrammetry, Remote Sensing & Spatial Information Sciences, IV-2/W5, pages 247-254.
